{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28745151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from url_parser import parse_url, get_url, get_base_url\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbe2bd",
   "metadata": {},
   "source": [
    "### 1. Break large file to 9 smaller ones: \n",
    "Run this in terminal:\n",
    "\n",
    "```split -l 500000 -a 4 dataset.json smaller_```\n",
    "\n",
    "Rename the files to `1 - 9.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b596392",
   "metadata": {},
   "source": [
    "### 2. Convert json to csv file with selected column names\n",
    "1. first convert all the individual json files to csv files\n",
    "2. get all the column names in all the files\n",
    "3. select which colums to use, and save those files to a csv folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78da8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_csv():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_json(f'../data/json/{i}.json', lines = True)\n",
    "        data.to_csv(f'../data/json/{i}.csv')\n",
    "\n",
    "def get_cols_name():\n",
    "    cols = set()\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_csv(f'../data/csv/{i}.csv', low_memory = False)\n",
    "        cols.update(data.columns.values.tolist())\n",
    "    return cols\n",
    "\n",
    "def use_cols_csv():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_csv(\n",
    "            f'../data/json/{i}.csv', \n",
    "            low_memory = False, \n",
    "            usecols = ['browserFamily', 'channel', 'deviceType', 'iabCategories', 'os', 'refDomain', 'url']\n",
    "        )\n",
    "        data.to_csv(f'../data/csv/{i}.csv')\n",
    "\n",
    "def json_to_csv(print_cols = False):\n",
    "    convert_json_csv()\n",
    "    if print_cols:\n",
    "        cols = get_cols_name()\n",
    "        pprint(cols)\n",
    "    use_cols_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff051f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [03:44<00:00, 24.97s/it]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:35<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "json_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d43b5",
   "metadata": {},
   "source": [
    "### 3. Clean csv file\n",
    "1. seperate labels and no labels\n",
    "2. save the no labels in a seperate folder\n",
    "3. explode/expand the iabcategories for each url -> one line per iabcategory per url\n",
    "4. add the scores (high, medium, low) for each\n",
    "5. break url into base, domain, path\n",
    "6. combine the channel, domain, path together in one \n",
    "7. remove stop words (open source and custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c4e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['www', 'www.', 'com', 'les', 'org', 'tag', 'html', 'id', 'un', 'win', \n",
    "                    'en', 'me', 'php', 'asp', 'aspx', 'cc', 'net']\n",
    "\n",
    "def get_iab_categories(iab_categories):\n",
    "    iab_categories_list = []\n",
    "    iab_categories = ast.literal_eval(iab_categories)\n",
    "    for iab_category in iab_categories:\n",
    "        for value in list(iab_category.values())[:-1]:\n",
    "            iab_categories_list.append([value, iab_category['score']])\n",
    "    return iab_categories_list\n",
    "\n",
    "def get_base_url_(url):\n",
    "    try:\n",
    "        return get_base_url(url)\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "def get_domain(url):\n",
    "    try:\n",
    "        domain = parse_url(url)['domain']\n",
    "    except:\n",
    "        domain = ' '.join(urlparse(url).netloc.split('.'))\n",
    "    try:\n",
    "        top_domain = parse_url(url)['top_domain'] or ''\n",
    "    except:\n",
    "        top_domain = ''\n",
    "    try:\n",
    "        sub_domain = parse_url(url)['sub_domain'] or ''\n",
    "    except:\n",
    "        sub_domain = ''\n",
    "    return domain + ' ' + sub_domain + ' ' + top_domain \n",
    "    \n",
    "def get_path(url):\n",
    "    try:\n",
    "        path = parse_url(url)['path']\n",
    "    except:\n",
    "        path = urlparse(url).path\n",
    "    return path\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop = []\n",
    "    stop.extend(stopwords.words('english'))\n",
    "    stop.extend(stopwords.words('french'))\n",
    "    stop.extend(stopwords.words('spanish'))\n",
    "    stop.extend(custom_stopwords)\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text)).strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in (stop)])\n",
    "    \n",
    "    return text\n",
    "    \n",
    "def clean_df(df, df_name):    \n",
    "    df_nolabel = df[df['iabCategories'].isnull()]\n",
    "    df_nolabel.to_csv(f'../data/clean/no_label/{df_name}.csv')\n",
    "    \n",
    "    df = df[~df['iabCategories'].isnull()]\n",
    "    df = df.fillna('')\n",
    "    df['iabCategories'] = df['iabCategories'].apply(get_iab_categories)\n",
    "    df = df.explode('iabCategories', ignore_index = True)\n",
    "    split = pd.DataFrame(df['iabCategories'].to_list(), columns = ['iab_categories', 'confidence'])\n",
    "    df = pd.concat([df, split], axis = 1)\n",
    "    df = df.drop('iabCategories', axis = 1)\n",
    "    df['base_url'] = df['url'].apply(get_base_url_)\n",
    "    df['domain'] = df['url'].apply(get_domain) \n",
    "    df['path'] = df['url'].apply(get_path)\n",
    "    df['combine'] = df['channel'] + ' ' + df['domain'] + ' ' + df['path']\n",
    "    df['combine'] = df['combine'].apply(remove_stop_words)\n",
    "    df.to_csv(f'../data/clean/label/{df_name}.csv')\n",
    "    \n",
    "def clean():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/csv/{i}.csv')\n",
    "        clean_df(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9d88c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 9/9 [4:04:58<00:00, 1633.20s/it]\n"
     ]
    }
   ],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06afe5",
   "metadata": {},
   "source": [
    "### 4. Get data ready for training\n",
    "\n",
    "1. look at all the columns\n",
    "2. get rid of unnessary cols\n",
    "3. look at all the unique values in certain columns\n",
    "4. replace them with numerical classes\n",
    "5. join all csv files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef517eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_name():\n",
    "    cols = set()\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/clean/label/{i}.csv', low_memory = False)\n",
    "        cols.update(df.columns.values.tolist())\n",
    "    return cols\n",
    "\n",
    "def drop_cols():\n",
    "    cols_to_drop = ['Unnamed: 0', 'base_url', 'channel', 'domain', 'path', 'refDomain', 'url']\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/clean/label/{i}.csv', low_memory = False)\n",
    "        df = df.rename(columns = {'Unnamed: 0.1': 'id'})\n",
    "        df = df.set_index('id')\n",
    "        df = df.drop(cols_to_drop, axis = 1)\n",
    "        df.to_csv(f'../data/train/{i}.csv')\n",
    "        \n",
    "def get_unique_vals():\n",
    "    unique_vals = {\n",
    "        'browserFamily': set(),\n",
    "        'deviceType': set(),\n",
    "        'os': set(),\n",
    "        'confidence': set()\n",
    "    }\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        for col in unique_vals.keys():\n",
    "            unique_vals[col].update(df[col].unique())\n",
    "    return unique_vals\n",
    "        \n",
    "    \n",
    "def display_df():\n",
    "    for i in range(1, 10):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        display(df.head())\n",
    "        print()\n",
    "        \n",
    "def combine():\n",
    "    dfs = []\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    combined_df.to_csv('../data/train/train_combined.csv', index=False)\n",
    "\n",
    "def group_val():\n",
    "    with open('../data/static_data/browser_family.pkl', 'rb') as f:\n",
    "        browser_family = pickle.load(f)\n",
    "    with open('../data/static_data/os.pkl', 'rb') as f:\n",
    "        os = pickle.load(f)\n",
    "    df = pd.read_csv('../data/train/train_combined.csv', low_memory = False)\n",
    "    df['browserFamily'] = df['browserFamily'].apply(lambda x: browser_family[x])\n",
    "    df['os'] = df['os'].apply(lambda x: os[x])\n",
    "    df.to_csv('../data/train/train_grouped.csv', index = False)\n",
    "    \n",
    "def replace_val():\n",
    "    df = pd.read_csv('../data/train/train_grouped.csv', low_memory = False)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['browserFamily'])\n",
    "    le_browser_family_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/browser_family_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_browser_family_mapping, f)\n",
    "    df['browserFamily'] = le.transform(df['browserFamily'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['deviceType'])\n",
    "    le_device_type_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/device_type_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_device_type_mapping, f)\n",
    "    df['deviceType'] = le.transform(df['deviceType'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['os'])\n",
    "    le_os_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/os_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_os_mapping, f)\n",
    "    df['os'] = le.transform(df['os'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['iab_categories'])\n",
    "    le_iab_categories_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/iab_categories_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_iab_categories_mapping, f)\n",
    "    df['iab_categories'] = le.transform(df['iab_categories'])\n",
    "    \n",
    "    df['confidence'] = df['confidence'].replace({'medium': 0.5, 'high': 1.0,})\n",
    "\n",
    "    df.to_csv('../data/train/train.csv', index = False)\n",
    "\n",
    "def get_train(show_cols = False, show_unique_vals = False):\n",
    "    if show_cols:\n",
    "        pprint(get_cols_name())\n",
    "    drop_cols()\n",
    "    if show_unique_vals:\n",
    "        pprint(get_unique_vals())\n",
    "    combine()\n",
    "    replace_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "042bc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f54d7c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>browserFamily</th>\n",
       "      <th>deviceType</th>\n",
       "      <th>os</th>\n",
       "      <th>iab_categories</th>\n",
       "      <th>confidence</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051580</th>\n",
       "      <td>15020</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>adj tdd st reward link IGsocial Aet Plg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085215</th>\n",
       "      <td>871980</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thejigsawpuzzles Animals Forest Scene jigsaw p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269724</th>\n",
       "      <td>128325</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>facebook usatoday billswire lists nfl teams su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227147</th>\n",
       "      <td>48105</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>oclc accessmedicine mhmedical uiwtx idm infogr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8426897</th>\n",
       "      <td>138526</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0.5</td>\n",
       "      <td>nodq news update former wwe star potentially r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961572</th>\n",
       "      <td>748337</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>google search geediting men low emotional inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877680</th>\n",
       "      <td>736281</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>revolvermag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632183</th>\n",
       "      <td>526441</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>foursome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319445</th>\n",
       "      <td>140403</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "      <td>scenepensacola shows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8105149</th>\n",
       "      <td>853234</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amac us poll concerning unsettling country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  browserFamily  deviceType  os  iab_categories  confidence  \\\n",
       "1051580   15020              3           5   3             157         1.0   \n",
       "7085215  871980              0           3   7             129         1.0   \n",
       "4269724  128325              3           5   0             150         1.0   \n",
       "5227147   48105              0           3   5             161         1.0   \n",
       "8426897  138526              3           5   0             161         0.5   \n",
       "6961572  748337              3           5   3              60         1.0   \n",
       "4877680  736281              3           5   3              13         1.0   \n",
       "3632183  526441              3           5   0              13         1.0   \n",
       "5319445  140403              3           5   3             150         0.5   \n",
       "8105149  853234              3           5   3             110         1.0   \n",
       "\n",
       "                                                   combine  \n",
       "1051580            adj tdd st reward link IGsocial Aet Plg  \n",
       "7085215  thejigsawpuzzles Animals Forest Scene jigsaw p...  \n",
       "4269724  facebook usatoday billswire lists nfl teams su...  \n",
       "5227147  oclc accessmedicine mhmedical uiwtx idm infogr...  \n",
       "8426897  nodq news update former wwe star potentially r...  \n",
       "6961572  google search geediting men low emotional inte...  \n",
       "4877680                                        revolvermag  \n",
       "3632183                                           foursome  \n",
       "5319445                               scenepensacola shows  \n",
       "8105149         amac us poll concerning unsettling country  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train/train.csv')\n",
    "df.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3b572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
