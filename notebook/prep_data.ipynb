{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28745151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from url_parser import parse_url, get_url, get_base_url\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbe2bd",
   "metadata": {},
   "source": [
    "### 1. Break large file to 9 smaller ones: \n",
    "Run this in terminal:\n",
    "\n",
    "```split -l 500000 -a 4 dataset.json smaller_```\n",
    "\n",
    "Rename the files to `1 - 9.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b596392",
   "metadata": {},
   "source": [
    "### 2. Convert json to csv file with selected column names\n",
    "1. first convert all the individual json files to csv files\n",
    "2. get all the column names in all the files\n",
    "3. select which colums to use, and save those files to a csv folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78da8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_csv():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_json(f'../data/json/{i}.json', lines = True)\n",
    "        data.to_csv(f'../data/json/{i}.csv')\n",
    "\n",
    "def get_cols_name():\n",
    "    cols = set()\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_csv(f'../data/csv/{i}.csv', low_memory = False)\n",
    "        cols.update(data.columns.values.tolist())\n",
    "    return cols\n",
    "\n",
    "def use_cols_csv():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        data = pd.read_csv(\n",
    "            f'../data/json/{i}.csv', \n",
    "            low_memory = False, \n",
    "            usecols = ['browserFamily', 'channel', 'deviceType', 'iabCategories', 'os', 'refDomain', 'url']\n",
    "        )\n",
    "        data.to_csv(f'../data/csv/{i}.csv')\n",
    "\n",
    "def json_to_csv(print_cols = False):\n",
    "    convert_json_csv()\n",
    "    if print_cols:\n",
    "        cols = get_cols_name()\n",
    "        pprint(cols)\n",
    "    use_cols_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff051f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [03:44<00:00, 24.97s/it]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:35<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "json_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d43b5",
   "metadata": {},
   "source": [
    "### 3. Clean csv file\n",
    "1. seperate labels and no labels\n",
    "2. save the no labels in a seperate folder\n",
    "3. explode/expand the iabcategories for each url -> one line per iabcategory per url\n",
    "4. add the scores (high, medium, low) for each\n",
    "5. break url into base, domain, path\n",
    "6. combine the channel, domain, path together in one \n",
    "7. remove stop words (open source and custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c4e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['www', 'www.', 'com', 'les', 'org', 'tag', 'html', 'id', 'un', 'win', \n",
    "                    'en', 'me', 'php', 'asp', 'aspx', 'cc', 'net']\n",
    "\n",
    "def get_iab_categories(iab_categories):\n",
    "    iab_categories_list = []\n",
    "    iab_categories = ast.literal_eval(iab_categories)\n",
    "    for iab_category in iab_categories:\n",
    "        for value in list(iab_category.values())[:-1]:\n",
    "            iab_categories_list.append([value, iab_category['score']])\n",
    "    return iab_categories_list\n",
    "\n",
    "def get_base_url_(url):\n",
    "    try:\n",
    "        return get_base_url(url)\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "def get_domain(url):\n",
    "    try:\n",
    "        domain = parse_url(url)['domain']\n",
    "    except:\n",
    "        domain = ' '.join(urlparse(url).netloc.split('.'))\n",
    "    try:\n",
    "        top_domain = parse_url(url)['top_domain'] or ''\n",
    "    except:\n",
    "        top_domain = ''\n",
    "    try:\n",
    "        sub_domain = parse_url(url)['sub_domain'] or ''\n",
    "    except:\n",
    "        sub_domain = ''\n",
    "    return domain + ' ' + sub_domain + ' ' + top_domain \n",
    "    \n",
    "def get_path(url):\n",
    "    try:\n",
    "        path = parse_url(url)['path']\n",
    "    except:\n",
    "        path = urlparse(url).path\n",
    "    return path\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop = []\n",
    "    stop.extend(stopwords.words('english'))\n",
    "    stop.extend(stopwords.words('french'))\n",
    "    stop.extend(stopwords.words('spanish'))\n",
    "    stop.extend(custom_stopwords)\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text)).strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in (stop)])\n",
    "    \n",
    "    return text\n",
    "    \n",
    "def clean_df(df, df_name):    \n",
    "    df_nolabel = df[df['iabCategories'].isnull()]\n",
    "    df_nolabel.to_csv(f'../data/clean/no_label/{df_name}.csv')\n",
    "    \n",
    "    df = df[~df['iabCategories'].isnull()]\n",
    "    df = df.fillna('')\n",
    "    df['iabCategories'] = df['iabCategories'].apply(get_iab_categories)\n",
    "    df = df.explode('iabCategories', ignore_index = True)\n",
    "    split = pd.DataFrame(df['iabCategories'].to_list(), columns = ['iab_categories', 'confidence'])\n",
    "    df = pd.concat([df, split], axis = 1)\n",
    "    df = df.drop('iabCategories', axis = 1)\n",
    "    df['base_url'] = df['url'].apply(get_base_url_)\n",
    "    df['domain'] = df['url'].apply(get_domain) \n",
    "    df['path'] = df['url'].apply(get_path)\n",
    "    df['combine'] = df['channel'] + ' ' + df['domain'] + ' ' + df['path']\n",
    "    df['combine'] = df['combine'].apply(remove_stop_words)\n",
    "    df.to_csv(f'../data/clean/label/{df_name}.csv')\n",
    "    \n",
    "def clean():\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/csv/{i}.csv')\n",
    "        clean_df(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9d88c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 9/9 [4:04:58<00:00, 1633.20s/it]\n"
     ]
    }
   ],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06afe5",
   "metadata": {},
   "source": [
    "### 4. Get data ready for training\n",
    "\n",
    "1. look at all the columns\n",
    "2. get rid of unnessary cols\n",
    "3. look at all the unique values in certain columns\n",
    "4. replace them with numerical classes\n",
    "5. join all csv files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef517eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_name():\n",
    "    cols = set()\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/clean/label/{i}.csv', low_memory = False)\n",
    "        cols.update(df.columns.values.tolist())\n",
    "    return cols\n",
    "\n",
    "def drop_cols():\n",
    "    cols_to_drop = ['Unnamed: 0', 'base_url', 'channel', 'domain', 'path', 'refDomain', 'url']\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/clean/label/{i}.csv', low_memory = False)\n",
    "        df = df.rename(columns = {'Unnamed: 0.1': 'id'})\n",
    "        df = df.set_index('id')\n",
    "        df = df.drop(cols_to_drop, axis = 1)\n",
    "        df.to_csv(f'../data/train/{i}.csv')\n",
    "        \n",
    "def get_unique_vals():\n",
    "    unique_vals = {\n",
    "        'browserFamily': set(),\n",
    "        'deviceType': set(),\n",
    "        'os': set(),\n",
    "        'confidence': set()\n",
    "    }\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        for col in unique_vals.keys():\n",
    "            unique_vals[col].update(df[col].unique())\n",
    "    return unique_vals\n",
    "        \n",
    "    \n",
    "def display_df():\n",
    "    for i in range(1, 10):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        display(df.head())\n",
    "        print()\n",
    "        \n",
    "def combine():\n",
    "    dfs = []\n",
    "    for i in tqdm(range(1, 10)):\n",
    "        df = pd.read_csv(f'../data/train/{i}.csv', low_memory = False)\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs, axis=0, ignore_index = True)\n",
    "    combined_df.to_csv('../data/train/train_combined.csv', index = False)\n",
    "\n",
    "def group_val():\n",
    "    with open('../data/static_data/browser_family.pkl', 'rb') as f:\n",
    "        browser_family = pickle.load(f)\n",
    "    with open('../data/static_data/os.pkl', 'rb') as f:\n",
    "        os = pickle.load(f)\n",
    "    df = pd.read_csv('../data/train/train_combined.csv', low_memory = False)\n",
    "    df['browserFamily'] = df['browserFamily'].apply(lambda x: browser_family[x])\n",
    "    df['os'] = df['os'].apply(lambda x: os[x])\n",
    "    df.to_csv('../data/train/train_grouped.csv', index = False)\n",
    "    \n",
    "def replace_val():\n",
    "    df = pd.read_csv('../data/train/train_grouped.csv', low_memory = False)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['browserFamily'])\n",
    "    le_browser_family_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/browser_family_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_browser_family_mapping, f)\n",
    "    df['browserFamily'] = le.transform(df['browserFamily'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['deviceType'])\n",
    "    le_device_type_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/device_type_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_device_type_mapping, f)\n",
    "    df['deviceType'] = le.transform(df['deviceType'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['os'])\n",
    "    le_os_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/os_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_os_mapping, f)\n",
    "    df['os'] = le.transform(df['os'])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['iab_categories'])\n",
    "    le_iab_categories_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    with open('../data/static_data/iab_categories_mapping.pkl', 'wb') as f:\n",
    "        pickle.dump(le_iab_categories_mapping, f)\n",
    "    df['iab_categories'] = le.transform(df['iab_categories'])\n",
    "    \n",
    "    df['confidence'] = df['confidence'].replace({'medium': 0.5, 'high': 1.0,})\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df.to_csv('../data/train/train.csv', index = False)\n",
    "\n",
    "def get_train(show_cols = False, show_unique_vals = False):\n",
    "    if show_cols:\n",
    "        pprint(get_cols_name())\n",
    "    drop_cols()\n",
    "    if show_unique_vals:\n",
    "        pprint(get_unique_vals())\n",
    "    combine()\n",
    "    replace_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042bc336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a2e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_alternate():\n",
    "    cols_to_drop = ['browserFamily', 'deviceType', 'os', 'combine']\n",
    "    le_iab_categories_mapping = pickle.load(open('../static_data/iab_categories_mapping.pkl', 'rb'))\n",
    "\n",
    "    df = pd.read_csv('../data/train/train_combined.csv', low_memory = False)\n",
    "    df = df.fillna('')\n",
    "    df['X'] = df['browserFamily'].str.lower() + ' ' + df['deviceType'].str.lower() + ' ' + df['os'].str.lower() + ' ' + df['combine'].str.lower()\n",
    "    df = df.drop(cols_to_drop, axis = 1)\n",
    "    \n",
    "    df['confidence'] = df['confidence'].replace({'medium': 0.5, 'high': 1.0,})\n",
    "    df['iab_categories'] = df['iab_categories'].replace(le_iab_categories_mapping)\n",
    "    df.to_csv('../data/train/train_alternate.csv', index = False)\n",
    "\n",
    "get_train_alternate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f54d7c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9122935, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>browserFamily</th>\n",
       "      <th>deviceType</th>\n",
       "      <th>os</th>\n",
       "      <th>iab_categories</th>\n",
       "      <th>confidence</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2636783</th>\n",
       "      <td>572294</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>movies watch tv genre thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83410</th>\n",
       "      <td>83632</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wowescape walkthrough flower find child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772417</th>\n",
       "      <td>537879</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>nubsnob cam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577445</th>\n",
       "      <td>446379</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>antenasport ru supersportpremier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070180</th>\n",
       "      <td>802220</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incestflix watch paintedrose homewrecking sist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758637</th>\n",
       "      <td>694454</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>berotak erp finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388740</th>\n",
       "      <td>153421</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aniwatch search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539630</th>\n",
       "      <td>341119</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>happeningmag bucks happening list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289417</th>\n",
       "      <td>53843</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linkedin timtebowfoundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377987</th>\n",
       "      <td>179079</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incestflix page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  browserFamily  deviceType  os  iab_categories  confidence  \\\n",
       "2636783  572294              3           5   3             106         1.0   \n",
       "83410     83632              0           3   7              75         1.0   \n",
       "7772417  537879              3           6   3              17         0.5   \n",
       "4577445  446379              0           3   4             150         1.0   \n",
       "9070180  802220              3           5   0              95         1.0   \n",
       "2758637  694454              3           5   3             118         1.0   \n",
       "7388740  153421              0           3   5              75         1.0   \n",
       "6539630  341119              3           5   3             161         1.0   \n",
       "7289417   53843              3           5   3              73         1.0   \n",
       "6377987  179079              3           5   3              95         1.0   \n",
       "\n",
       "                                                   combine  \n",
       "2636783                     movies watch tv genre thriller  \n",
       "83410              wowescape walkthrough flower find child  \n",
       "7772417                                        nubsnob cam  \n",
       "4577445                   antenasport ru supersportpremier  \n",
       "9070180  incestflix watch paintedrose homewrecking sist...  \n",
       "2758637                                berotak erp finance  \n",
       "7388740                                    aniwatch search  \n",
       "6539630                  happeningmag bucks happening list  \n",
       "7289417                        linkedin timtebowfoundation  \n",
       "6377987                                    incestflix page  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train/train.csv')\n",
    "pprint(df.shape)\n",
    "df.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d753fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9143493, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>iab_categories</th>\n",
       "      <th>confidence</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7182812</th>\n",
       "      <td>969577</td>\n",
       "      <td>157</td>\n",
       "      <td>0.5</td>\n",
       "      <td>chrome mobile smartphone ios camcaps io video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709275</th>\n",
       "      <td>457360</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chrome personal computer windows bing search b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074692</th>\n",
       "      <td>968950</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mobile safari smartphone ios kentonline co uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164171</th>\n",
       "      <td>1022772</td>\n",
       "      <td>145</td>\n",
       "      <td>0.5</td>\n",
       "      <td>chrome personal computer linux antenasport ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958294</th>\n",
       "      <td>921734</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chrome mobile smartphone android creationflix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514886</th>\n",
       "      <td>514886</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>android browser smartphone android listapp pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896542</th>\n",
       "      <td>896542</td>\n",
       "      <td>118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chrome personal computer android google search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809528</th>\n",
       "      <td>772968</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chrome personal computer windows myflixertv home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637974</th>\n",
       "      <td>637974</td>\n",
       "      <td>88</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mobile safari tablet ios facebook p us collect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906386</th>\n",
       "      <td>727344</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mobile safari smartphone ios soap dayto ww day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  iab_categories  confidence   \n",
       "7182812   969577             157         0.5  \\\n",
       "7709275   457360             150         1.0   \n",
       "4074692   968950              31         1.0   \n",
       "5164171  1022772             145         0.5   \n",
       "1958294   921734              76         1.0   \n",
       "514886    514886             150         1.0   \n",
       "896542    896542             118         1.0   \n",
       "1809528   772968              13         1.0   \n",
       "637974    637974              88         0.5   \n",
       "5906386   727344             150         1.0   \n",
       "\n",
       "                                                         X  \n",
       "7182812  chrome mobile smartphone ios camcaps io video ...  \n",
       "7709275  chrome personal computer windows bing search b...  \n",
       "4074692      mobile safari smartphone ios kentonline co uk  \n",
       "5164171      chrome personal computer linux antenasport ru  \n",
       "1958294  chrome mobile smartphone android creationflix ...  \n",
       "514886   android browser smartphone android listapp pla...  \n",
       "896542   chrome personal computer android google search...  \n",
       "1809528   chrome personal computer windows myflixertv home  \n",
       "637974   mobile safari tablet ios facebook p us collect...  \n",
       "5906386     mobile safari smartphone ios soap dayto ww day  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train/train_alternate.csv')\n",
    "pprint(df.shape)\n",
    "df.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f79d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
