{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sharhad.bashar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, FeatureHasher, TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'browserFamily', 'deviceType', 'os', 'iab_categories',\n",
      "       'confidence', 'combine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load your data from the CSV file\n",
    "df = pd.read_csv('../data/train/train.csv')\n",
    "pprint(df.columns)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df[['browserFamily', 'deviceType', 'os', 'combine']]\n",
    "y = df['iab_categories']\n",
    "confidence_scores = df['confidence']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, confidence_train, confidence_test = train_test_split(X, y, confidence_scores, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7298348, 4) (7298348,) (7298348,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, confidence_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(X, col = 'name_title'):\n",
    "    vectorizer = CountVectorizer(stop_words = 'english')\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def one_hot_encoding(X, col = 'name_title'):\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    X = X.values.reshape(-1, 1)\n",
    "    X = one_hot_encoder.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def word_2_vector(X):\n",
    "    w2v_model = gensim.models.Word2Vec(X, vector_size = 100, window = 5, min_count = 2)\n",
    "\n",
    "def glove(X):\n",
    "    return X\n",
    "\n",
    "def tfidf(X, col = 'name_title'):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = 0.8, max_features = 10000)\n",
    "    return tfidf_vectorizer.fit_transform(X[col])\n",
    "\n",
    "def countvector_tfidtransform(X, col = ''):\n",
    "    cv = CountVectorizer(stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    X = cv.fit_transform(X[col])\n",
    "    return tfidf.fit_transform(X)\n",
    "    # pipeline = Pipeline([\n",
    "    #     ('vect', CountVectorizer(stop_words = 'english')),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    # ])\n",
    "    # return pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ColumnTransformer to separately process text and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('text', CountVectorizer(), 'combine'),\n",
    "        ('categorical', OneHotEncoder(), ['browserFamily', 'deviceType', 'os'])\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "# Create a pipeline with the preprocessor and SGDClassifier\n",
    "clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(loss = 'log', random_state = 42, class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer()),\n",
    "#     ('scaler', StandardScaler(with_mean = False)),\n",
    "#     ('classifier', SGDClassifier(loss = 'log', random_state = 42, class_weight = 'balanced'))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, classifier__sample_weight = confidence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
