{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sharhad.bashar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, FeatureHasher, TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'browserFamily', 'deviceType', 'os', 'iab_categories',\n",
      "       'confidence', 'combine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load your data from the CSV file\n",
    "df = pd.read_csv('../data/train/train.csv')\n",
    "pprint(df.columns)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df[['browserFamily', 'deviceType', 'os', 'combine']]\n",
    "y = df['iab_categories']\n",
    "confidence_scores = df['confidence']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, confidence_train, confidence_test = train_test_split(X, y, confidence_scores, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7298348, 4) (7298348,) (7298348,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, confidence_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(X, col = 'name_title'):\n",
    "    vectorizer = CountVectorizer(stop_words = 'english')\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def one_hot_encoding(X, col = 'name_title'):\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    X = X.values.reshape(-1, 1)\n",
    "    X = one_hot_encoder.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def word_2_vector(X):\n",
    "    w2v_model = gensim.models.Word2Vec(X, vector_size = 100, window = 5, min_count = 2)\n",
    "\n",
    "def glove(X):\n",
    "    return X\n",
    "\n",
    "def tfidf(X, col = 'name_title'):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = 0.8, max_features = 10000)\n",
    "    return tfidf_vectorizer.fit_transform(X[col])\n",
    "\n",
    "def countvector_tfidtransform(X, col = ''):\n",
    "    cv = CountVectorizer(stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    X = cv.fit_transform(X[col])\n",
    "    return tfidf.fit_transform(X)\n",
    "    # pipeline = Pipeline([\n",
    "    #     ('vect', CountVectorizer(stop_words = 'english')),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    # ])\n",
    "    # return pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ColumnTransformer to separately process text and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('text', CountVectorizer(), 'combine'), #replace with TfidfVectorizer\n",
    "        ('categorical', OneHotEncoder(), ['browserFamily', 'deviceType', 'os'])\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "# Create a pipeline with the preprocessor and SGDClassifier\n",
    "clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(loss = 'log', random_state = 42, class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer()),\n",
    "#     ('scaler', StandardScaler(with_mean = False)),\n",
    "#     ('classifier', SGDClassifier(loss = 'log', random_state = 42, class_weight = 'balanced'))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y_train, classifier__sample_weight = confidence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09055583537534796\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDClassifier Accuracy: 0.14313814578312792 -> 32 min\n",
    "\n",
    "LogisticRegression Accuracy: 0.35889656124920327 -> 319 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, classifier_name):\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('text', CountVectorizer(), 'combine'), \n",
    "            ('categorical', OneHotEncoder(), ['browserFamily', 'deviceType', 'os'])\n",
    "        ],\n",
    "        remainder = 'passthrough'\n",
    "    )\n",
    "    clf = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train, classifier__sample_weight = confidence_train)\n",
    "    end = time.time() - start\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return classifier_name, accuracy, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Email:\n",
    "    def __init__(self):\n",
    "        config = json.load(open('../config/email.json'))\n",
    "        self.name = config['name']\n",
    "        self.sender = config['sender']\n",
    "        self.to = config['to']\n",
    "        self.token = config['token']\n",
    "\n",
    "    def send_email(self, subject, message):\n",
    "        msg = MIMEText(message)\n",
    "        msg['To'] = self.to\n",
    "        msg['From'] = self.sender\n",
    "        msg['Subject'] = subject\n",
    "        \n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp_server:\n",
    "            smtp_server.login(self.sender, self.token)\n",
    "            smtp_server.sendmail(self.sender, self.to, msg.as_string())\n",
    "            \n",
    "# email = Email()\n",
    "# classifier_name = 'log'\n",
    "# accuracy = 0.09055583537534796\n",
    "# end = 1232\n",
    "# message = f'{classifier_name} has an accuracy of {round(accuracy, 5)} and took {end} to run'\n",
    "# email.send_email('subject', message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfiers = [\n",
    "    [RandomForestClassifier(class_weight = 'balanced'), 'random forest'],\n",
    "    [LogisticRegression(class_weight = 'balanced'), 'logistic regression'],\n",
    "    [SGDClassifier(loss = 'log', random_state = 42, class_weight = 'balanced'), 'sgd classifier'],\n",
    "    [LinearSVC(class_weight = 'balanced'), 'linear svc'],\n",
    "    [GradientBoostingClassifier(), 'g boost'],\n",
    "    [KNeighborsClassifier(), 'k neighbor'],\n",
    "    [DecisionTreeClassifier(class_weight = 'balanced'), 'decision tree'],\n",
    "    [MLPClassifier(), 'mlp classifier'],\n",
    "    [MultinomialNB(), 'multinomial nb']\n",
    "]\n",
    "\n",
    "for classifier, classifier_name in classfiers:\n",
    "    classifier_name, accuracy, end = train(classifier, classifier_name)\n",
    "    print(classifier_name, accuracy, end)\n",
    "    email = Email()\n",
    "    message = f'{classifier_name} has an accuracy of {round(accuracy, 5)} and took {end} to run'\n",
    "    email.send_email(classifier_name, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
